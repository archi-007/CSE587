{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-tRYS5kF67XZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX6zsN5i7iG2",
        "outputId": "d1d3c9ba-08ab-48c2-e899-d367e52f30a2"
      },
      "outputs": [],
      "source": [
        "path_to_file = tf.keras.utils.get_file(\"shakespeare.txt\",\n",
        "                                       \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\")\n",
        "\n",
        "text = open(path_to_file, \"r\", encoding=\"utf-8\").read()\n",
        "lines = text.split(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6xrxZAT7lth",
        "outputId": "5900a215-45b6-4741-a8b9-123e347072de"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(total_words)\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for line in lines:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        input_sequences.append(token_list[:i+1]) \n",
        "\n",
        "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding=\"pre\")\n",
        "\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "\n",
        "embedding_dim = 50\n",
        "embedding_index = {}\n",
        "\n",
        "with open(\"glove.6B.50d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.array(values[1:], dtype=\"float32\")\n",
        "        embedding_index[word] = vector\n",
        "\n",
        "embedding_matrix = np.zeros((total_words, embedding_dim))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIp9Bo-c98OJ",
        "outputId": "be94c8b8-7568-4996-9c27-d5b622385997"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Embedding(total_words, embedding_dim, weights=[embedding_matrix], input_length=max_sequence_length-1, trainable=True),\n",
        "    LSTM(256, return_sequences=True),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    LSTM(64),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "    Dense(total_words, activation=\"softmax\")\n",
        "]) ##LSTM\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OXULE74hA1A",
        "outputId": "0de443d9-5971-4efb-c370-838673690b63"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_cnn_lstm = Sequential([\n",
        "    Embedding(total_words, embedding_dim, input_length=max_sequence_length-1, trainable=True),\n",
        "    Conv1D(filters=256, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    LSTM(256, return_sequences=True),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    LSTM(64),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "    Dense(total_words, activation=\"softmax\")\n",
        "]) ##CNN+LSTM\n",
        "\n",
        "model_cnn_lstm.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7bWxR98p9_fb",
        "outputId": "8de0eaf9-6e81-453b-fafd-c410e40376b7"
      },
      "outputs": [],
      "source": [
        "model.fit(X, y, epochs=100, verbose=1, batch_size=64)\n",
        "# model_cnn_lstm.fit(X, y, epochs=10, verbose=1, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b_0-jeBqWV1"
      },
      "outputs": [],
      "source": [
        "def generate_text(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding=\"pre\")\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8l8IajjqXE0"
      },
      "outputs": [],
      "source": [
        "print(generate_text(\"The night was dark\", next_words=20))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
